{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Camera Analysis for RenderMe360 s3_all\n",
    "\n",
    "This notebook provides interactive tools for exploring camera configurations and testing different subset selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, Image, HTML\n",
    "import ipywidgets as widgets\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Add script directory to path\n",
    "sys.path.append('/ssd2/zhuoyuan/renderme360_temp/download_all/process_data_scripts')\n",
    "from analyze_s3_cameras_dynamic import DynamicCameraAnalyzer\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Analyze Camera Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subject directories\n",
    "base_dir = Path('/ssd2/zhuoyuan/renderme360_temp/download_all/subjects')\n",
    "subjects = ['0018', '0019', '0026']\n",
    "subject_dirs = [base_dir / subj for subj in subjects]\n",
    "\n",
    "# Create analyzer\n",
    "print(\"Analyzing camera data...\")\n",
    "analyzer = DynamicCameraAnalyzer(subject_dirs)\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nAnalysis complete!\")\n",
    "print(f\"Subjects analyzed: {len(analyzer.subjects_data)}\")\n",
    "print(f\"Common cameras across all subjects: {len(analyzer.common_cameras)}\")\n",
    "print(f\"\\nCommon camera IDs: {analyzer.common_cameras}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Camera Position Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics from first subject\n",
    "subject_id = list(analyzer.subjects_data.keys())[0]\n",
    "metrics = analyzer.subjects_data[subject_id]['metrics']\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "metrics_df = pd.DataFrame([\n",
    "    {\n",
    "        'Camera ID': cam_id,\n",
    "        'X (m)': m['position'][0],\n",
    "        'Y (m)': m['position'][1],\n",
    "        'Z (m)': m['position'][2],\n",
    "        'Distance (m)': m['distance'],\n",
    "        'Azimuth (°)': m['azimuth_deg'],\n",
    "        'Elevation (°)': m['elevation_deg']\n",
    "    }\n",
    "    for cam_id, m in metrics.items()\n",
    "])\n",
    "\n",
    "# Display statistics\n",
    "print(\"Camera Position Statistics:\")\n",
    "print(\"=\"*50)\n",
    "display(metrics_df.describe())\n",
    "\n",
    "# Show first few cameras\n",
    "print(\"\\nFirst 10 cameras:\")\n",
    "display(metrics_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive 3D Camera Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Create interactive 3D plot\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get positions\n",
    "positions = np.array([metrics[cam_id]['position'] for cam_id in sorted(metrics.keys())])\n",
    "cam_ids = sorted(metrics.keys())\n",
    "\n",
    "# Plot cameras\n",
    "scatter = ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2],\n",
    "                    c=positions[:, 2], cmap='viridis', s=100, alpha=0.6)\n",
    "\n",
    "# Add labels\n",
    "for i, cam_id in enumerate(cam_ids):\n",
    "    ax.text(positions[i, 0], positions[i, 1], positions[i, 2],\n",
    "            str(cam_id), fontsize=8)\n",
    "\n",
    "# Add subject at origin\n",
    "ax.scatter([0], [0], [0], color='red', s=200, marker='*', label='Subject')\n",
    "\n",
    "ax.set_xlabel('X (m)')\n",
    "ax.set_ylabel('Y (m)')\n",
    "ax.set_zlabel('Z (m)')\n",
    "ax.set_title('Interactive 3D Camera Positions')\n",
    "ax.legend()\n",
    "\n",
    "plt.colorbar(scatter, ax=ax, label='Height (m)', pad=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Coverage Gap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coverage gaps\n",
    "gaps = analyzer.analyze_coverage_gaps()\n",
    "\n",
    "# Create DataFrame\n",
    "gaps_df = pd.DataFrame(gaps)\n",
    "\n",
    "print(\"Coverage Gap Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Average gap: {np.mean(gaps_df['gap_degrees']):.1f}°\")\n",
    "print(f\"Ideal gap for {len(metrics)} cameras: {360/len(metrics):.1f}°\")\n",
    "print(f\"\\nLargest gaps:\")\n",
    "display(gaps_df.head(10))\n",
    "\n",
    "# Plot gap distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(gaps_df['gap_degrees'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=np.mean(gaps_df['gap_degrees']), color='red', linestyle='--', label='Average')\n",
    "plt.xlabel('Gap Size (degrees)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Angular Gaps Between Cameras')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Camera Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widget for subset selection\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_subset(num_cameras, show_labels=True):\n",
    "    \"\"\"Visualize a camera subset selection.\"\"\"\n",
    "    suggestions = analyzer.suggest_optimal_subsets([num_cameras])\n",
    "    \n",
    "    if num_cameras not in suggestions:\n",
    "        print(f\"Cannot create subset of {num_cameras} cameras\")\n",
    "        return\n",
    "    \n",
    "    subset = suggestions[num_cameras]\n",
    "    selected_cams = subset['cameras']\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # 1. Top-down view\n",
    "    ax1 = axes[0]\n",
    "    for cam_id, m in metrics.items():\n",
    "        pos = m['position']\n",
    "        if cam_id in selected_cams:\n",
    "            ax1.scatter(pos[0], pos[1], color='red', s=100, alpha=0.8)\n",
    "            if show_labels:\n",
    "                ax1.annotate(str(cam_id), (pos[0], pos[1]), fontsize=8, fontweight='bold')\n",
    "        else:\n",
    "            ax1.scatter(pos[0], pos[1], color='lightgray', s=30, alpha=0.3)\n",
    "    \n",
    "    ax1.scatter(0, 0, color='blue', s=200, marker='*')\n",
    "    ax1.set_xlabel('X (m)')\n",
    "    ax1.set_ylabel('Y (m)')\n",
    "    ax1.set_title('Top-Down View')\n",
    "    ax1.axis('equal')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Polar view\n",
    "    ax2 = plt.subplot(132, projection='polar')\n",
    "    for cam_id, m in metrics.items():\n",
    "        if cam_id in selected_cams:\n",
    "            ax2.scatter(m['azimuth_rad'], m['distance'], color='red', s=100, alpha=0.8)\n",
    "            if show_labels:\n",
    "                ax2.annotate(str(cam_id), (m['azimuth_rad'], m['distance']), \n",
    "                           fontsize=8, fontweight='bold')\n",
    "        else:\n",
    "            ax2.scatter(m['azimuth_rad'], m['distance'], color='lightgray', s=30, alpha=0.3)\n",
    "    ax2.set_title('Angular Distribution')\n",
    "    \n",
    "    # 3. Metrics display\n",
    "    ax3 = axes[2]\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    # Display metrics as text\n",
    "    metrics_text = f\"\"\"Camera Subset Metrics\n",
    "    {'='*25}\n",
    "    Cameras: {num_cameras}\n",
    "    Selected IDs: {selected_cams}\n",
    "    \n",
    "    Coverage Metrics:\n",
    "    - Average gap: {subset['avg_gap']:.1f}°\n",
    "    - Max gap: {subset['max_gap']:.1f}°\n",
    "    - Min gap: {subset['min_gap']:.1f}°\n",
    "    - Gap std: {subset['gap_std']:.1f}°\n",
    "    \n",
    "    Quality Score: {subset['quality_score']:.1f}/100\n",
    "    \n",
    "    Storage Estimates:\n",
    "    - Per subject: {subset['storage_per_subject_gb']:.1f} GB\n",
    "    - 500 subjects: {subset['storage_500_subjects_gb']:.0f} GB\n",
    "    \"\"\"\n",
    "    \n",
    "    ax3.text(0.1, 0.5, metrics_text, transform=ax3.transAxes, \n",
    "            fontsize=10, verticalalignment='center', fontfamily='monospace')\n",
    "    \n",
    "    plt.suptitle(f'Camera Subset Visualization - {num_cameras} Cameras', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return selected_cams\n",
    "\n",
    "# Create interactive widget\n",
    "camera_slider = widgets.IntSlider(\n",
    "    value=12,\n",
    "    min=4,\n",
    "    max=20,\n",
    "    step=2,\n",
    "    description='Cameras:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "labels_checkbox = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show Labels'\n",
    ")\n",
    "\n",
    "widgets.interact(visualize_subset, num_cameras=camera_slider, show_labels=labels_checkbox);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Different Subset Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different subset sizes\n",
    "subset_sizes = [4, 6, 8, 10, 12, 16, 20]\n",
    "suggestions = analyzer.suggest_optimal_subsets(subset_sizes)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for size, data in suggestions.items():\n",
    "    comparison_data.append({\n",
    "        'Cameras': size,\n",
    "        'Avg Gap (°)': f\"{data['avg_gap']:.1f}\",\n",
    "        'Max Gap (°)': f\"{data['max_gap']:.1f}\",\n",
    "        'Quality Score': f\"{data['quality_score']:.1f}\",\n",
    "        'Storage/Subject (GB)': f\"{data['storage_per_subject_gb']:.1f}\",\n",
    "        'Storage/500 (TB)': f\"{data['storage_500_subjects_gb']/1024:.1f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"Camera Subset Comparison:\")\n",
    "print(\"=\"*70)\n",
    "display(comparison_df)\n",
    "\n",
    "# Plot storage vs quality\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Storage plot\n",
    "storage_values = [suggestions[s]['storage_500_subjects_gb']/1024 for s in subset_sizes]\n",
    "ax1.plot(subset_sizes, storage_values, 'o-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Cameras')\n",
    "ax1.set_ylabel('Storage for 500 Subjects (TB)')\n",
    "ax1.set_title('Storage Requirements')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='1TB limit')\n",
    "ax1.axhline(y=2, color='orange', linestyle='--', alpha=0.5, label='2TB limit')\n",
    "ax1.legend()\n",
    "\n",
    "# Quality plot\n",
    "quality_values = [suggestions[s]['quality_score'] for s in subset_sizes]\n",
    "ax2.plot(subset_sizes, quality_values, 'o-', linewidth=2, markersize=8, color='green')\n",
    "ax2.set_xlabel('Number of Cameras')\n",
    "ax2.set_ylabel('Quality Score')\n",
    "ax2.set_title('Coverage Quality')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Custom Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config_yaml(num_cameras):\n",
    "    \"\"\"Generate config.yaml snippet for a specific camera count.\"\"\"\n",
    "    suggestions = analyzer.suggest_optimal_subsets([num_cameras])\n",
    "    \n",
    "    if num_cameras not in suggestions:\n",
    "        print(f\"Cannot generate config for {num_cameras} cameras\")\n",
    "        return\n",
    "    \n",
    "    selected_cameras = suggestions[num_cameras]['cameras']\n",
    "    \n",
    "    config = f\"\"\"# Configuration for {num_cameras} cameras in s3_all\n",
    "# Quality Score: {suggestions[num_cameras]['quality_score']:.1f}/100\n",
    "# Storage: {suggestions[num_cameras]['storage_per_subject_gb']:.1f} GB per subject\n",
    "# Total for 500 subjects: {suggestions[num_cameras]['storage_500_subjects_gb']:.0f} GB\n",
    "\n",
    "extraction:\n",
    "  # Camera selection for s3_all\n",
    "  cameras: {selected_cameras}\n",
    "  \n",
    "  # Extract only s3_all with these cameras\n",
    "  performances:\n",
    "    - \"s3_all\"\n",
    "  \n",
    "  # Data modalities to extract\n",
    "  modalities:\n",
    "    - \"metadata\"\n",
    "    - \"calibration\"\n",
    "    - \"images\"\n",
    "    - \"audio\"\n",
    "\n",
    "# For single-view performances, run separately with:\n",
    "# cameras: [25]\n",
    "# performances: [\"s1_all\", \"s2_all\", \"s4_all\", \"s5_all\", \"s6_all\"]\n",
    "\"\"\"\n",
    "    \n",
    "    print(config)\n",
    "    \n",
    "    # Also save to file\n",
    "    output_file = f\"config_s3all_{num_cameras}_cameras.yaml\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(config)\n",
    "    print(f\"\\nConfiguration saved to: {output_file}\")\n",
    "\n",
    "# Interactive widget for config generation\n",
    "config_slider = widgets.IntSlider(\n",
    "    value=12,\n",
    "    min=4,\n",
    "    max=20,\n",
    "    step=2,\n",
    "    description='Cameras:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Generate Config\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        generate_config_yaml(config_slider.value)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "display(widgets.VBox([config_slider, button, output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all camera positions to CSV\n",
    "output_dir = Path('/ssd2/zhuoyuan/renderme360_temp/download_all/visualizations/camera_analysis')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save camera metrics\n",
    "metrics_df.to_csv(output_dir / 'camera_metrics.csv', index=False)\n",
    "print(f\"Camera metrics saved to: {output_dir / 'camera_metrics.csv'}\")\n",
    "\n",
    "# Save gap analysis\n",
    "gaps_df.to_csv(output_dir / 'coverage_gaps.csv', index=False)\n",
    "print(f\"Coverage gaps saved to: {output_dir / 'coverage_gaps.csv'}\")\n",
    "\n",
    "# Save subset recommendations\n",
    "comparison_df.to_csv(output_dir / 'subset_recommendations.csv', index=False)\n",
    "print(f\"Subset recommendations saved to: {output_dir / 'subset_recommendations.csv'}\")\n",
    "\n",
    "print(\"\\nAll analysis results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides interactive tools for:\n",
    "1. Analyzing camera positions and coverage\n",
    "2. Testing different subset configurations\n",
    "3. Generating configuration files\n",
    "4. Visualizing camera arrangements\n",
    "\n",
    "### Key Findings:\n",
    "- All subjects have the same 38 cameras in s3_all\n",
    "- Camera distribution has some irregularities (large gaps)\n",
    "- 12 cameras provides good balance of quality and storage\n",
    "- Different subset sizes suit different research needs\n",
    "\n",
    "### Next Steps:\n",
    "1. Choose appropriate subset size based on storage constraints\n",
    "2. Update config.yaml with selected cameras\n",
    "3. Run extraction for remaining subjects\n",
    "4. Monitor storage usage during extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}